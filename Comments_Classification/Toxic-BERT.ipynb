{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация комментариев с BERT и TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Цели:\n",
    "* Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "* Постройте модель со значением метрики качества *F1* не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm, notebook\n",
    "tqdm.pandas(desc=\"progress bar!\")\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer \n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('popular', quiet=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:0.3f}'.format\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим сбалансированность выборки.\n",
    "\n",
    "* Токсичных комментариев намного меньше.\n",
    "* Присутствует дисбаланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.898\n",
       "1   0.102\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts() / df.toxic.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим текст при помощи регулярных выражений. Это впоследствии пригодится для tf-idf с CatBoost и поможет провести проверку на дубликаты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ограничим число символов - 5000. Этого достаточно для задачи и поможет увеличить скорость расчетов.\n",
    "def clear_text(text, char_limit=5000):\n",
    "    # Приведем текст к нижнему регистру очистив его от лишних символов и цифр.\n",
    "    text = re.sub(r\"[^a-z']\", ' ', text.lower())\n",
    "    \n",
    "    # Обрежим сообщение до ближайшего целого слова.\n",
    "    try:\n",
    "        r = re.match(r'(?P<truncated> .+) \\s', text[:char_limit], re.X)\n",
    "        text = r['truncated'].split()\n",
    "        return ' '.join(text)\n",
    "    except:\n",
    "        return 'empty line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Датафрейм для tf-idf с CatBoost.\n",
    "df2vec = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww he matches this background colour i'm se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i'm really not trying to edit war it's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can't make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d'aww he matches this background colour i'm se...      0\n",
       "2  hey man i'm really not trying to edit war it's...      0\n",
       "3  more i can't make any real suggestions on impr...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2vec['text'] = df2vec['text'].map(clear_text).copy()\n",
    "df2vec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим дубликаты и удалим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1356"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2vec['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158215, 2) (158215, 2)\n"
     ]
    }
   ],
   "source": [
    "df = df[~df2vec['text'].duplicated()]\n",
    "df2vec = df2vec[~df2vec['text'].duplicated()]\n",
    "\n",
    "print(df.shape, df2vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем текст при помощи лемматизатора Wordnet из NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем WordNetLemmatizer.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Функция для определения формы речи перед лемматизацией.\n",
    "def get_wordnet_pos(word):\n",
    "    # nltk.pos_tag() возвращает кортеж с тегом POS.\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# Функция лемматизации.\n",
    "def lemmatize(text):\n",
    "    return ' '.join(\n",
    "        [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация процесс долгий. Воспользуемся pickle для сохранения и загрузки её результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('lemmatized_test.pickle', 'rb') as f:\n",
    "        df2vec['text'] = pickle.load(f)\n",
    "except:\n",
    "    df2vec['text'] = df2vec['text'].progress_apply(lemmatize)\n",
    "    with open('lemmatized_test.pickle', 'wb') as f:\n",
    "        pickle.dump(df2vec['text'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим два новых признака: число уникальных слов и количество символов в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2vec['comment_rich'] = df2vec['text'].str.split().map(lambda x: len(set(x)))\n",
    "df2vec['comment_len'] = df2vec['text'].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем последовательное обучением различных моделей для получения более подробного отчета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку и сформируем Pool'ы для CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df2vec.drop('toxic', axis=1),\n",
    "    df2vec['toxic'],\n",
    "    test_size=0.2,\n",
    "    stratify=df2vec['toxic'],\n",
    "    random_state=38)\n",
    "\n",
    "train_set = Pool(X_train, y_train, text_features=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры.\n",
    "params = {\n",
    "    'objective': 'Logloss',\n",
    "    'loss_function': 'Logloss',\n",
    "    'task_type': 'GPU',\n",
    "    'devices': '0:1',\n",
    "    'depth': 6,\n",
    "    'scale_pos_weight': 1.5,\n",
    "    'random_strength': 0.2,\n",
    "    'l2_leaf_reg': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iterations           999.000\n",
       "test-Logloss-mean      0.142\n",
       "test-Logloss-std       0.004\n",
       "train-Logloss-mean     0.130\n",
       "train-Logloss-std      0.003\n",
       "Name: 999, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_data = cv(\n",
    "    pool=train_set,\n",
    "    params=params,\n",
    "    early_stopping_rounds=100,\n",
    "    logging_level='Silent',\n",
    "    fold_count=3,\n",
    "    stratified=True,\n",
    "    partition_random_seed=38\n",
    ")\n",
    "\n",
    "# Результаты кросс-валидации.\n",
    "cv_data.iloc[-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим метрики на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6515623\ttotal: 58.9ms\tremaining: 58.9s\n",
      "250:\tlearn: 0.1569367\ttotal: 2.51s\tremaining: 7.49s\n",
      "500:\tlearn: 0.1459845\ttotal: 4.82s\tremaining: 4.8s\n",
      "750:\tlearn: 0.1398743\ttotal: 7.13s\tremaining: 2.36s\n",
      "999:\tlearn: 0.1353803\ttotal: 9.43s\tremaining: 0us\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     28424\n",
      "           1       0.85      0.76      0.80      3219\n",
      "\n",
      "    accuracy                           0.96     31643\n",
      "   macro avg       0.91      0.87      0.89     31643\n",
      "weighted avg       0.96      0.96      0.96     31643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cb = CatBoostClassifier(random_state=38, **params)\n",
    "cb.fit(train_set, verbose=250)\n",
    "\n",
    "print()\n",
    "print(classification_report(y_test, cb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подгрузим стоп слова.\n",
    "nltk_stopwords = stopwords.words('english')\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    # Векторизация TF-IDF текстовых данных.\n",
    "    [('text', TfidfVectorizer(max_df=0.85,\n",
    "                              # stop_words = nltk_stopwords,\n",
    "                              max_features=6000), 'text')],\n",
    "    # Остальные признаки оставляем как есть.\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126572, 6002) (31643, 6002)\n"
     ]
    }
   ],
   "source": [
    "X_train_vec = ct.fit_transform(X_train)\n",
    "X_test_vec = ct.transform(X_test)\n",
    "\n",
    "print(X_train_vec.shape, X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем основные метрики полученные у LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     28424\n",
      "           1       0.84      0.76      0.80      3219\n",
      "\n",
      "    accuracy                           0.96     31643\n",
      "   macro avg       0.91      0.87      0.89     31643\n",
      "weighted avg       0.96      0.96      0.96     31643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000,\n",
    "                        class_weight={0: 1, 1: 1.5},\n",
    "                        n_jobs=-1,\n",
    "                        C=6,\n",
    "                        random_state=38)\n",
    "lr.fit(X_train_vec, y_train)\n",
    "print(classification_report(y_test, lr.predict(X_test_vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT - unitary/toxic-bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать AutoModel и AutoTokenizer из библиотеки transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Зададим модель, она как раз заточена под toxic comments.\n",
    "model_name = 'unitary/toxic-bert'\n",
    "\n",
    "# Загрузим предобученную PyTorch модель.\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Модель будем просчитвать используюя GPU.\n",
    "torch.device('cuda')\n",
    "model.to('cuda:0');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отредактируем настройки, в частности поменяем problem_type с мультиклассовой классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config = model.config.from_dict(\n",
    "    {\n",
    "        'id2label': {'0': 'not_toxic', '1': 'toxic'},\n",
    "        'label2id': {'not_toxic': '0', 'toxic': '1'},\n",
    "        'problem_type': 'single_label_classification',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем данные. На выходе получим input tokens и маску значимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, _, attention_mask = tokenizer(df['text'].values.tolist(),\n",
    "                                         return_tensors='pt',\n",
    "                                         max_length=384, # ограничим длину, иначе всё очень долго считается.\n",
    "                                         padding=True, \n",
    "                                         truncation=True).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем окончательные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('features_full.pickle', 'rb') as f:\n",
    "        features = pickle.load(f)    \n",
    "except:\n",
    "    # Количесто батчей чтобы не забить всю память расчетами.\n",
    "    batch_size = 100\n",
    "    size = df.shape[0]\n",
    "    embeddings = []\n",
    "\n",
    "    for i in notebook.tqdm(range(size // batch_size + (size % batch_size != 0))):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids[batch_size*i:batch_size*(i+1)].cuda(),\n",
    "                            attention_mask=attention_mask[batch_size*i:batch_size*(i+1)].cuda())\n",
    "            # Найдем среднее в выходном тензоре.\n",
    "            outputs_mean = torch.mean(outputs[0], dim=1)\n",
    "            embeddings.append(outputs_mean)\n",
    "            \n",
    "    # Выгружаем наши данные обратно на CPU.\n",
    "    features = np.concatenate([x.cpu() for x in embeddings])\n",
    "    \n",
    "    # Сохраняем их.\n",
    "    with open('features_full.pickle', 'wb') as f:\n",
    "        pickle.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158215, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбивка навыборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(features, df['toxic'], test_size=0.2, random_state=38, stratify=df['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     28424\n",
      "           1       0.95      0.95      0.95      3219\n",
      "\n",
      "    accuracy                           0.99     31643\n",
      "   macro avg       0.97      0.97      0.97     31643\n",
      "weighted avg       0.99      0.99      0.99     31643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(n_jobs=-1)\n",
    "lr.fit(X_train, y_train)\n",
    "print(classification_report(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6129486\ttotal: 11.6ms\tremaining: 11.5s\n",
      "250:\tlearn: 0.0324055\ttotal: 2.94s\tremaining: 8.79s\n",
      "500:\tlearn: 0.0274462\ttotal: 5.7s\tremaining: 5.68s\n",
      "750:\tlearn: 0.0239816\ttotal: 8.43s\tremaining: 2.79s\n",
      "999:\tlearn: 0.0212323\ttotal: 11.2s\tremaining: 0us\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     28424\n",
      "           1       0.94      0.96      0.95      3219\n",
      "\n",
      "    accuracy                           0.99     31643\n",
      "   macro avg       0.97      0.97      0.97     31643\n",
      "weighted avg       0.99      0.99      0.99     31643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cb.fit(X_train, y_train, verbose=250)\n",
    "\n",
    "print()\n",
    "print(classification_report(y_test, cb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "* Получена модель, классифицирующая комментарии на позитивные и негативные.\n",
    "* Достигнута f1 ~ 0.95 на тестовой выборке благодаря правильно выбранной модели unitary/toxic-bert.\n",
    "* Проведено сравнение BERT, CatBoostClassifier и TF-IDF based.\n",
    "    * Если доступно много ресурсов и нужна повышенная точность, то лучше всего использовать трасформеры.\n",
    "    * Если требуется быстрый результат из коробки, то побеждает CatBoostClassifier.\n",
    "* Векторизация и последующая классификация TF-IDF показала себя неплохо, но возможно следует выбрать другой классификатор для достижения более высоких результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
